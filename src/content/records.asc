
== Tables and records

Part of the philosophy of `morloc` is that we start by looking at actual use
cases and describing what we want to be able to do. Once the requirements are
discovered, we look for a theoretical framework that elegantly supports them.
Once the theory is found, the syntax and particulars of the original
requirements may be refined. This refinement may lead to even better solutions
than our originally imagined solutions. Sometimes we may find that what we
originally wanted, however, is not theoretically possible. Or that the added
complexity is not worth the convenience.

Since `morloc` is intended to be used with data analysis, elegant handling of
Tables, and more generally Records, is essential. 

To describe the issues, I will focus on the description of the diamonds dataset
commonly used in the R community. I will work from the simplest possible type
representation to the most expressive. I will not consider here the separate
problem of reading a table from text where we must deal with separators and
quotation. There are many possible sources for a table: text, database queries,
excel files, direct construction etc.

The simplest type would be `Table`. This type would imply that the data is a
table and nothing more. It might support the following functions:

 * `read :: String -> String -> Table` - read a table with a given separator  
 * `nrows :: Table -> Nat` - returns number of rows
 * `ncols :: Table -> Nat` - returns number of columns
 * `cuts :: Table -> [Nat] -> Table*` - extract smaller table (may fail)

Notably, we cannot define a `colnames` function that gets the column names
since it is not known whether the table has a header. For the same reason,
`nrows` may be off by one.

We could add column names and types as a record parameter to the Table type:

----
Table {
 carat :: Real,
 cut :: String,
 color :: String,
 clarity :: String
}
----

For brevity, I am eliding the final 5 fields (table, price, x, t, z). We could
definitely be more specific with the column types. For example the `cut`,
`color` and `clarity` columns could be better represented as algrebraic data
types:

----
Table {
 carat :: Real,
 cut :: Fair | Good | VeryGood | Premium | Ideal,
 color :: E | I | J | H | F | G | D,
 clarity :: SI2 | SI1 | VS1 | VS2 | VVS2 | VVS1 | I1 | IF
}
----

We could also add constraints such as `carat > 0`, but the typing of the
columns is not a problem unique to tables, so I will only say we have a single
record describing the column types.

In the type expression above, we only specify the types of cells in each
column. From the type expression itself, we could not know that the table
consists of multiple rows.


What if some cells need additional annotations? Or all values in a column must
be unique? Or maybe we want to preserve the color-coding from a loaded excel
file. What if the column names are not syntactically legal keyword names (e.g.,
"carat - the size of the diamond"). What if we need to specify that a given
column is the "key" column?

Rather than creating a new base type `Table` we could describe our table as a
special kind of list. A table may be represented in two general ways:
column-wise and row-wise. The column-wise representation of a table is a record
with one entry for each column. Each entry is a homogeneous list of a given
length. The columns are constrained to all have the same number of elements.
The natural way to encode column names is as field names in the record. The
row-wise representation stores a list of tuples. This representation is cleaner
in theory since no constraint is needed to ensure columns are of equal length.
However, in practice, the column-wise representation is far more common.

Choosing the row-wise implementation, we could write:

----
[{
  carat :: Real,
  cut :: Fair | Good | VeryGood | Premium | Ideal,
  color :: E | I | J | H | F | G | D,
  clarity :: SI2 | SI1 | VS1 | VS2 | VVS2 | VVS1 | I1 | IF
}]
----

The column-wise type can be written as:

----
{
  carat :: [Real]_n,
  cut :: [Fair | Good | VeryGood | Premium | Ideal]_n,
  color :: [E | I | J | H | F | G | D]_n,
  clarity :: [SI2 | SI1 | VS1 | VS2 | VVS2 | VVS1 | I1 | IF]_n,
}
----

Notice that added syntax `_n` for specifying the length of a list. I've been
toying with adding this cardinality constraint for awhile. Arguments against it
include the idea in Haskell that lists are not special, they are simply one
kind of functor. And why should I add special syntax and complexity just for
one type? However, from a Lisp perspective, lists are EVERYTHING, so the
special syntax makes more sense. However, the `_n` syntax is could apply to
more than just a list, and could be used for anything with a size (e.g.,
elements in a set or nodes in a graph). It could extend to multiple dimensions
as well.

A problem with the row-wise and column-wise type specifications, is that they
lose the notion of "tableness". There may be types that should not be
interpreted as tables that are also lists of records or records comprised of
fields of equal-length lists. Complex types should not usually go into tables.
Also, many languages have special handling and optimizations for tables and
morloc tables should compile into these structures where possible. If we do not
have a dedicated Table type, then `morloc` will have to infer when a data type
should be treated as a Table object. Since this decision is often subjective,
it should be left to the programmer. Therefore, I think we should go with the
dedicated Table type.

There more issues to consider with the Table type, but they mostly distill down
to issues with record types. This is true since a table consists of many
records, so any quality we use to describe a record can be easily extended to
describe a table. Likewise, any operation on a record or set of records can be
extended unambiguously (maybe) to a table or set of tables. Therefore, I will
now segue to the topic of records and afterwards come back to talk about how it
relates to tables.

=== Records

The most simple type of record is an unordered list of named values. For
example, the description of a package:

----
{
 authors :: [String],
 maintainer :: String,
 packageName :: String,
 packageDescription :: String,
 date :: Date
}
----

Let's say we want to write a function takes a list of package configs and
returns a table of packages and their authors:

----
maintainerTable :: [{
       authors :: [String],
       maintainer :: String,
       packageName :: String,
       packageDescription :: String,
       date :: Date
    }]
 -> Table {packageName :: String, maintainer :: String} 
----

This is REALLY ugly. Why should we have to specify all fields in the config
file when we only need two of them? Of course we could use an alias to define
`Config` as the 5 field record. But this doesn't solve the problem.

The fundamental issue we are dealing with here is the old debate between open
and closed worlds. SQL is a closed world where only the data specified in the
schemas may be represented. SPARQL (and whole semantic web paradigm) is an open
world where the schemas only specify what behavior must be allowed, but do not
limit what can be said. The world of data science if often quite open and
strict schemas are often too brittle for practical use.

But I am not sure I want to a full open world. Not yet at least.

One option would be to add record subsetting where input records may contain
additional fields but are still allowed so long as all required fields are
present. In this case, we could simply write:

----
maintainerTable' :: [{maintainer :: String, packageName :: String}]
 -> Table {maintainer :: String, packageName :: String}
----

But here it is not clear that some fields are omitted. I also lose the ability
to make closed records. So I could add unlabeled named fields that represent
additional fields may exist.

----
maintainerTable'' :: [{maintainer :: String, packageName :: String, _}]
 -> Table {maintainer :: String, packageName :: String}
----

Here I use "_" as the name, indicating more fields may exist but I do not care
what they are.

Closed records correspond to C structures, which are extremely memory
efficient. So it is nice to be able to specify when they are closed. Open
records introduce the problem of heterogenous lists.

Another feature I want is to have optional default values for fields in records, for example:

----
{
 authors :: [String],
 maintainer :: String ? "You",
 packageName :: String,
 packageDescription :: String ? "See README",
 date :: Date
}
----

In Haskell, records are just constructors with access functions generated for
them. With the extensions described above, this is clearly not the case anymore
for `morloc`.

=== Extending record operations to tables

The open-world and default-value extensions of records described in the
previous section are particularly useful in the context of tables.

Suppose we want to join two tables based on a common ID. We might write this
function as:

----
join => Eq val
     :: n1:Table left
     -> n2:Table right
     -> key:String
     -> n3:Table final
  where {
      nrows n3 <= nrows n1
    , nrows n3 <= nrows n2
    , key in left
    , key in right
    , key in final
    , unique (n1[key])
    , unique (n2[key])
    , unique (n3[key])
    , intersect left right = {}
  }
----
