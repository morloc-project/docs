== Pieces

[NOTE]
Currently this is not how `morloc` is implemented. Previously I did parse
directly to RDF and then collect the data needed for generation using SPARQL
queries. This proved to be complicated and the path to full typechecking using
some sort of rule engine seemed hard, so I refactored the parser to generate a
more conventional abstract syntax tree. This allows more direct implementation
of type systems. I currently use the bidirectional typing algorithm as
described by Dunsfield, but generalized to work with multiple simultaneous
languages. I plan to eventually replace this with a rule engine that reads from
RDF, but I will probably not make that jump until I've ironed out the
difficulties in the code generators and basic F system implementation.

. Parser
The local parser that generates RDF from whatever flavor of morloc script (or
MorlocStudio or any other tool) they happen to be using. The output though is
MAST (MorlocScript Abstract Syntax Tree). MAST needs a formal specification
that is respected by every parser. There may be a parser-specific ruleset for
cleaning the generated RDF (which may be influenced by the implementation of
the parser) into MAST. Alternatively, the parser may create some other output
that is then converted by whatever means into MAST. Anyway, all that really
matters that MAST is the final output. The RDF morloc currently generates
roughly corresponds to MAST (it needs a lot of refinement, though).

. Semantic Engine (SE)
Next the MAST is passed through a semantic engine (SE). There will be default
rulesets for typechecking and inference (light on both counts). The morloc
script writer may also specify in the script (this is not yet supported) which
rulesets to use. The SE does type checking and type casting. It further removes
the temporary data structures used in MAST, thus generating the abstract syntax
tree that describes the abstract program (VAST, Very Abstract Syntax Tree). It
is VAST that is stored in MorlocIO.

. "Linker"
When a user decides to generate an executable from a morloc program (i.e. a
VAST file) they need to first merge data from their local system (which is RDF
also) with the VAST file. Then we can start trying to link functions to
concrete sources. This is where dependencies are handled. The final output is a
CAST file (Concrete Abstract Syntax Tree). The CAST file contains all the
information needed to generate an executable on the local system.

. Generator
The final step is to compile the CAST file into an exectuable.  This involves
generating the nexus file and all required pools.  Alternatively, it may
involve (as directed by CAST) the generation of Common Workflow Language
scripts or other possible outputs. The final executable will probably not be
portable (i.e., it will probably have hard-coded paths to resources).

. UI
This fifth piece is the interface to the previous 4 steps. On the command
line, it is the `morloc` program. For GUI users, it is `MorlocStudio` (which
will probably be built on top of `morloc`).  This piece handles local
configurations (i.e. generating the aforementioned RDF description of the local
system); all IO operations; dependency checking; downloading, uploading and
managing packages; generating local package templates and checking them; etc
etc etc.


== Another phrasing

.Compiler
given an ontology, database of typed functions, and an application, it
generates code to allow the functions to talk across languages and builds a
nexus to integrate them.

.Environment
`morloc` is intended to allow tools and languages to be interoperable. The user
should be able to import a function from any language and expect it to run. For
this to work, the compiler needs to have the languages and tools installed. The
user should not have to install all this.  Instead, they work through Docker.
Inside the Docker image, everything they need is present. When a new program is
installed, the code is sent to the docker image, everything is built in there
and run in there. The local executable is an API to the docker image. Or
something. I seriously need to prototype this.

.Semantic type system (STS)
a language for ascribing sufficient semantic information to data and functions
that an AI can automate every sort of tedious work.

.Knowledgebase

.Packager
A knowledge-base describing the relations between all data types and storing
all functions.
